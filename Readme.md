# ğŸ¬ Neural Storyboard Generator

Turn any written story into a complete visual storyboard using AI-powered scene extraction and image generation.

---

## ğŸš€ Overview

**Neural Storyboard Generator** is an end-to-end pipeline that transforms a story into **scene captions**, generates **AI images** for each scene using **Stable Diffusion**, and composes them into **paginated storyboard pages**.

This project enables:

* Preâ€‘production storyboarding
* Creative writing visualization
* Animation and film planning
* Rapid prototyping for games & comics

---

## ğŸ§© System Architecture

### **1. Input Layer (Streamlit UI)**

* User enters story text
* Generates a session ID for output
* Triggers AI pipeline when "Generate Storyboard" is clicked
* Displays scenes, generated panels, and storyboard pages

### **2. Scene Processing Layer**

Performed by `scene_splitter.py`:

* Cleans text (removes tags, extra spaces)
* Splits text into sentences using regex
* Groups sentences into meaningful scene captions (â‰¥5 words)
* Applies `MAX_SCENES` limit

### **3. Image Generation Layer**

Handled by `image_generator.py` using Stable Diffusion:

* Converts caption text to CLIP embeddings
* Generates deterministic noise latents using seeded generators
* Runs UNet denoising (25 steps)
* VAE decodes latent â†’ final 512Ã—512 image
* Saves images as `panel_XX.png`

### **4. Storyboard Rendering Layer**

Handled by `storyboard_renderer.py`:

* Places images into 3Ã—3 grids
* Writes captions underneath
* Dynamically adjusts page height
* Exports multiâ€‘page storyboards as PNG or optional PDF

### **5. Output Layer**

Directory structure:

```
outputs/
   <session_id>/
      images/
      storyboards/
```

Provides downloadable storyboard pages.

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py                     # Streamlit UI
â”œâ”€â”€ main.py                    # CLI entrypoint
â”œâ”€â”€ config.py                  # Global configuration
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ scene_splitter.py      # Scene extraction logic
â”‚   â”œâ”€â”€ image_generator.py     # Stable Diffusion wrapper
â”‚   â”œâ”€â”€ storyboard_renderer.py # Storyboard page creator
â”‚   â””â”€â”€ utils.py               # Directory helpers
â”œâ”€â”€ outputs/                   # Auto-generated files
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/neural-storyboard-generator.git
cd neural-storyboard-generator
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Download Stable Diffusion v1.5

Place the SD v1.5 model in your HuggingFace cache directory:

```
~/.cache/huggingface/diffusers/runwayml/stable-diffusion-v1-5/
```

Or edit `SD_MODEL` in `config.py`.

### 4. Run the Streamlit App

```bash
streamlit run app.py
```

---

## ğŸ§  How It Works (Detailed)

### **A) Scene Extraction**

* Cleans the raw input
* Splits text into sentences
* Forms scenes with a minimum word count

### **B) CLIP Embedding (Inside Stable Diffusion)**

* Captions are tokenized
* Transformer text encoder â†’ CLIP embeddings
* Embeddings guide UNet during denoising

### **C) Diffusion Process**

1. Start with pure random Gaussian noise
2. UNet predicts noise to remove
3. 25 iterative denoising steps refine the latent
4. VAE decodes final latent â†’ RGB image

### **D) Storyboard Creation**

* Combines images and captions
* Builds multiâ€‘page storyboards
* Saves pages as PNG/PDF

---

## ğŸ–¼ï¸ Example Output

* Extracted scene captions
* Individual image panels
* Storyboard pages (page_01.png, page_02.png, ...)

---

## ğŸ› ï¸ Configuration (`config.py`)

```python
DEVICE = "cuda"
MAX_SCENES = 128
T5_MODEL = "t5-small"     # (Not used but kept for expansion)
SD_MODEL = "runwayml/stable-diffusion-v1-5"
OUTPUT_DIR = "outputs"
HF_TOKEN_ENV = "HF_TOKEN"
```

---

## ğŸ§ª Command-Line Usage

```bash
python main.py
```

Enter a story when prompted. The pipeline runs endâ€‘toâ€‘end.

---

## ğŸ“ Roadmap

* [ ] Optional LLM scene enhancer
* [ ] Character consistency across panels
* [ ] More rendering layouts (2Ã—2, comic style, manga style)
* [ ] Built-in PDF export with custom covers
* [ ] Style presets (anime, sketch, noir, cinematic)

---

## ğŸ¤ Contributing

Pull requests are welcome. Please maintain modular code structure.

---

## ğŸ“„ License

MIT License â€” free for both personal and commercial use.
